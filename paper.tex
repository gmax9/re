\PassOptionsToPackage{table}{xcolor}
\documentclass[manuscript,nonacm]{acmart}
% \documentclass[sigconf,anonymous]{acmart}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

\usepackage{amsmath}
\let\Bbbk\relax
\usepackage{amssymb}
\let\Bbbk\relax
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{marvosym}
\usepackage{threeparttable}
\usepackage{textgreek}
\usepackage{paralist}
\usepackage{filecontents}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{tikz,siunitx}
\usetikzlibrary{shapes.geometric,shapes.symbols}
\usepackage{threeparttable}
\usepackage{enumerate}
\usepackage{comment}
\usepackage{arydshln}
\usepackage{enumitem}

\newcommand{\mybox}[4]{
    \begin{figure}[h]
        \centering
    \begin{tikzpicture}
        \node[anchor=text,text width=\columnwidth-1.5em, draw, rounded corners, line width=1pt, fill=#3, inner sep=1em, inner ysep=0.5em] (big) {\\#4};
        % \node[draw, rounded corners, line width=.5pt, fill=#2, anchor=west, xshift=5mm] (small) at (big.north west) {#1};
    \end{tikzpicture}
    \end{figure}
}

% Commands for Surveyed Works Table
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\markA}{\ding{66}}%
\newcommand{\markB}{\ding{71}}%
\newcommand{\markC}{\ding{75}}%
\newcommand{\markD}{\ding{168}}%
\newcommand{\markE}{\ding{169}}%
\newcommand{\markF}{\ding{170}}%
\newcommand{\markG}{\ding{171}}%
\newcommand{\markH}{\ding{92}}%
\newcommand{\markI}{\ding{214}}%
\newcommand{\markJ}{\ding{166}}%
\newcommand{\markX}{\Sagittarius} % heh
\newcommand{\markY}{\Virgo}
\newcommand{\markZ}{\Moon}
\newcommand{\markEtc}{\textbf{?}}
\def\rot{\rotatebox}
\newcommand*\circled[1]{\tikz[baseline=-3pt]{
            \node (X) [shape=circle,scale=0.5,fill=black,text=white,font=\bfseries, text centered, draw,inner sep=0pt] {\strut #1};}}
\newcommand{\notcheckmark}{{$\surd$}\textsuperscript{\textcolor{black}{\kern-0.35em{\bf--}}}}
            
\newcommand{\wc}[1]{\textit{\textcolor{magenta}{#1}}} % Word-Choice macro
\newcommand{\maxnote}[1]{\textit{\textcolor{violet}{#1 --Max}}}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\begin{document}

\title{A Survey of Darknet Detection Methodologies: Design, Implementation, and Assessment}
\author{Max Gao}
% \authornote{Both authors contributed equally to this research.}
\affiliation{%
  \institution{CAIDA/UC San Diego}
  \city{San Diego}
  \state{CA}
  \country{USA}
}
\email{magao@ucsd.edu}

\begin{abstract}
Network telescope (darknet) traffic has been instrumental in providing visibility into Internet-wide phenomena related to security and availability such as malicious scanning, denial-of-service (DoS) backscatter, and outages. 
To better operationalize darknets for their monitoring capabilities, researchers have proposed a number of automated detection methodologies which span a diverse set of analytical techniques applied to different features of darknet traffic. 
Yet despite the abundance of methods, a comprehensive view of their comparative capabilities remains unclear due to gaps across their implementations and inconsistencies across their empirical assessments. 
In this report, we review the evolution of darknet event detection methodologies over the past decade and examine in-depth the challenges that face a comprehensive, systematic assessment. We conclude with a discussion of future directions to address these challenges.
% Yet despite the abundance of methods, their comparative capabilities remain unclear due to limited labeled datasets, difficultings in replicating their implementations, and the lack of a unified validation approach.
% In this report, we review the evolution of darknet detection methodologies over the past decade and examine in-depth the challenges that face a comprehensive, systematic assessment.
% We conclude with a discussion of future directions for improving assessment rigor and method comparability.
    
% Analysis of network telescope, or darknet, traffic has provided substantial visibility into the security and availability of the Internet for decades.
% To operationalize darknet monitoring capabilities, researchers have proposed numerous frameworks that automate the detection of Internet-wide events.
% Despite an abundance of available frameworks, less attention has been directed towards systematic comparison of their capabilities. 
% As a result, \dots
% In this report, we survey existing work that proposes and evaluates such frameworks on real-world darknet traffic.
% We review tasks that motivate the techniques each framework employs as well as experimental details of their evaluation; and finally, discuss future \dots
% To more effectively operationalize network telescopes for monitoring the security and availability of the Internet, researchers have proposed a diverse body of frameworks which codify empirical post-hoc analysis techniques.
% Yet, \dots
\end{abstract}

\maketitle

\section{Introduction}

Network telescopes, or darknets, have been instrumental to both researchers and practitioners for their ability to observe Internet-wide phenomena in the unsolicited traffic they receive. 
Over the past two decades, research efforts have shifted from characterizing darknet phenomena and their observable signals towards translating such empirical insights into operationalizable methodologies for monitoring the Internet's security and availability in near real-time.
These efforts have culminated in a number of methodologies that, despite sharing a common goal of automatically detecting events from darknet traffic, 
differ widely in the technique(s) they employ (\textit{e.g.,} dimensionality reduction, forecasting, representation learning), features of the traffic they exploit (\textit{e.g.,} packet inter-arrival times, destination port sequences), and their operational definition of what constitutes an event (\textit{e.g.,} a shift in sender clusters, anomalous traffic volumes towards specific ports). 
As recent studies propose an increasing number of methods that leverage machine-learning techniques,
systematic assessment of their capabilities are needed to enable fair yet rigorous comparisons
to determine their effectiveness in-practice.
However as our report finds, many of these methods have been developed, implemented, and 
assessed independently by different research groups without necessary standard procedures to ensure
their comparability.
As a result, this lack of standardization discourages the development of new and existing methods
which we encountered in our prior work~\cite{2024gao}.
% However, many of these methodologies have been developed, implemented, and assessed independently by different research groups without a uniform standard for best-practices. 
% This fragmentation discourages the development of new or improvement to existing methodologies due to several challenges that we encountered in our prior work~\cite{2024gao} and later describe in this report.

In this report, we survey an extensive body of literature that proposes darknet event detection methodologies to investigate the extent that the challenges we encountered impact the development and assessments of darknet-event detection methodologies at large. 
Overall, we find a low degree of replicability among proposed methodologies and inconsistencies across datasets and validation approaches in their assessments.
Section 1 provides an overview of canonical literature that characterizes darknet traffic and its associated phenomena.
We discuss notable findings from past empirical studies and their role in monitoring darknet traffic. 
Section 2 introduces our taxonomy of detection methodologies with a breakdown of their detected events, employed techniques, and the features and representations of their traffic inputs alongside 
summarized intuitions guiding their design.
Section 3 reviews empirical assessments of prior work separate from methods themselves to highlight specific gaps that result from the lack of standard practices. 
Finally, we conclude our survey's findings with directions for future work intended 
to support more robust evidence-informed method selection for darknet event detection tasks 
by enabling systematic comparative assessments.



% As we experienced while designing and evaluating our prior work, DarkSim~\cite{2024gao}, this challenge takes form in limited replicability of implementations, inconsistent approaches to validation, and non-standardized metrics for measuring performance.

\begin{comment}
% Network telescopes, or darknets, have been instrumental to both researchers and practitioners for their ability to observe Internet-wide phenomena in the unsolicited traffic they receive. 
% Over the past two decades, research efforts have shifted from characterizing darknet phenomena and their observable signals towards translating such empirical insights into operationalizable methodologies for monitoring the Internet's security and availability in near real-time.
% This has resulted in a number of methodologies that each leverage different approaches to achieve a common goal of broadly automating darknet event detection. 
% \maxnote{see other papers for enumerating on specific details in intro} As security risks mount along growing volumes of darknet traffic, such methodologies represents a crucial and necessary transition from conventional post-hoc manual traffic analysis workflows. 
% However, the utility of these methodologies depend critically on their accuracy and validity which remain elusive to evaluate due to several challenges that we identify through our survey. 
% These efforts have resulted in a variety of methodologies that share the common goal of broadly automating event detection while differing widely in the algorithmic techniques they employ (e.g., statistical forecasting, matrix decompositions, and graph-based models), 
% the traffic features they exploit (e.g., packet counts, port sequences, temporal bursts), 
% and their operational definition of what constitutes an event (ranging from short-lived scans to sustained probing campaigns).
% As security risks mount along growing volumes of darknet traffic, such methodologies represent a crucial and necessary transition from post-hoc manual traffic analysis towards a more \maxnote{dots} means of detection.
% However, the utility of these frameworks depend critically on their accuracy and validity, which remain elusive to evaluate due challenges posed by \dots.

% However, as we identify in our suvey, methodologies differ widely in several ways: the algorithmic techniques they employ (e.g., statistical forecasting, matrix decompositions, and graph-based models), the traffic features they exploit (e.g., packet counts, port sequences, temporal bursts), 
% and their operational definition of what constitutes an event (ranging from short-lived scans to sustained probing campaigns).

% Network telescopes, or darknets, have been instrumental to both researchers and practitioners due to their capacity to observe Internet-wide phenomena in the unsolicited traffic they receive. 
% The visibility afforded by these observatories have enabled significant progress in the areas of cybersecurity and censorship, evident in a rich body of work that centers around the study of malicious scanning, denial-of-service attacks, and Internet outages. 
% The visibility afforded by these observatories have enabled significant progress in the areas of cybersecurity and censorship, evident in a rich body of work centered around 
% malicious scanning, denial-of-service events, and Internet outages. 

% Over the past two decades, research efforts have shifted from characterizing darknet phenomena and their observable signals towards translating such empirical insights into operationalizable frameworks for monitoring the Internet's security and availability in near real-time.  
% This has led to the development of a number of frameworks that each share the common goal of automating the detection of events in darknet traffic while taking notably different approaches to doing so\maxnote{feedback: elaborate on the specifics here.}.
% As security risks mount along with growing volumes of darknet traffic, such frameworks represent a crucial and necessary transition from conventional post-hoc manual traffic analysis workflows.
% However, the utility of these frameworks, particularly those more recent that leverage machine learning techniques, depend critically on their accuracy and validity which remain elusive to evaluate due to challenges posed by the diversity of framework detection objectives and approaches.

% As a result, a number of frameworks that each share a common goal of automating event detection within darknet traffic have been proposed.
% This has resulted in a number of proposed frameworks that share a common goal of automating the detection of events within darknet traffic.
% \begin{enumerate}
%   \item Overview of topic - 2 sentences.
%   \item 
%   \item Summary of contributions - 3 sentences.
% \end{enumerate}

% Network telescopes, or darknets, have been instrumental to both researchers and practitioners due to their capacity to observe Internet-wide phenomena in the unsolicited traffic they receive.
% Over the past two decades, research efforts have shifted from characterizing such phenomena and their observable signals towards translating these empirical insights into operationalizable frameworks for monitoring the Internet's security and availability in near real-time.

% Network telescopes, or darknets, have been instrumental to both researchers and practitioners due to their capacity to observe Internet-wide phenomena in the unsolicited traffic they receive.
% Over the past two decades, research efforts have shifted from characterizing such phenomena and their observable signals towards translating empirical insights into operationalizable frameworks for monitoring the Internet's security and availability in near real-time.
% As a result, a large variety of frameworks have been proposed. 
% Each share the same general goal of automating event detection.
% They vary widely in their choice of techniques and selection of darknet traffic features as they are designed with different event definitions in mind.
% \textit{discuss why it's difficult to speculate on their performance without further empirical evaluation.}

% Despite the variety of available frameworks for darknet traffic analysis, selecting the most suitable framework off-the-shelf for a given darknet is challenging.
% While the variety of frameworks is frank

% Traffic Growth
% Complexity Growth - new 
\end{comment}

% In this report, we survey an extensive body of literature that proposes darknet event detection methodologies to investigate the extent to which challenges we encountered extend to method assessment at large.
% Section 1 first provides an overview of canonical literature that characterizes darknet traffic and discusses major findings of previous studies. 
% Section 2 introduces our taxonomy of detection methodologies that breaks down their components and highlights the intuitions underlying each of their approaches.
% Section 3 reviews the empirical assessments of methods, identifying gaps that currently obscure a complete picture of the comparative capabilities between methods.
% We conclude our survey's findings with directions for future work aimed at enabling more rigorous, systematic assessments.

% In this report, we survey an extensive body of literature that proposes darknet event detection methodologies to investigate the extent to which challenges we encountered likewise extend to method assessment at large. 
% We begin with an overview of canonical literature that \dots in Section~\ref{sec:bg} .
% We then describe our taxonomy of methodologies in Section~\ref{sec:frameworks}, blah blah intution.
% In Section~\ref{sec:assessments}, we review their empirical assessments to identify gaps that prevent \dots.
% Finally, Section~\ref{sec:fw} closes our report with a discussion of future work we intend in order to enable more rigorous, systematic assessments of darknet event detection methodologies.

% In this report, we survey an extensive body of literature on darknet event detection methodologies to investigate the extent that the challenges we encountered affect this topic of research at large. 
% We begin with an overview of prior work that characterizes network telescope traffic and chronicles its major changes in Section~\ref{sec:bg}.
% We then describe our taxonomy of methodologies in Section~\ref{sec:frameworks}, comparing\dots\maxnote{brief summary}, followed by a review of their evaluation in Section~\ref{sec:assessments}.
% Finally, using our survey's findings, we conclude with a discussion of challenges in this area as well as directions for future work in Section~\ref{sec:fw}.

% In this report, we survey an extensive body of literature to construct a taxonomy of darknet event detection methodologies followed by a separate taxonomy that details their assessments in empirical evaluations. 
% We begin with an overview of prior work that characterizes network telescope traffic and chronicles its major changes in Section~\ref{sec:bg}.
% We then describe our taxonomy of methodologies in Section~\ref{sec:frameworks}, comparing\dots\maxnote{brief summary}, followed by a review of their evaluation in Section~\ref{sec:assessments}.
% Finally, using our survey's findings, we conclude with a discussion of challenges in this area as well as directions for future work in Section~\ref{sec:fw}.

% We begin this report with an overview of network telescopes, the traffic they collect, and the types of Internet-wide events inferrable through analysis of such traffic.
% We then survey various frameworks that have been proposed to automate event detection and construct a taxonomy that compares their 1) analysis goals and designs; and 2) performance as informed by empirical evaluations on real-world darknet traffic.
% Using this taxonomy, we identify challenges and opportunities for future research where efforts may yield improvements over the current state-of-art.

% \clearpage

\label{sec:bg}
\section{Background}
In this section, we provide a brief overview of network telescopes and discuss their role in Internet measurement research.
We first provide a technical explanation of their function as observatories of unsolicited IPv4 Internet traffic.
We then summarize findings from past works that have studied the nature and composition of this traffic during landmark Internet-wide events.
Finally, we remark on changes in characteristics of such traffic up to present day and speculate on the future development of its traffic and flows.

% \label{sec:bg:nt}
% \subsection{Network Telescopes}

\begin{figure*}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/traffic_growth.pdf}
    \caption{Growth in volumes of darknet-traffic collected at UCSD-NT over 15 years. Daily compressed PCAP filesizes have exceeded 3.5 terabytes per day.}
    \label{fig:traffic_growth}
\end{figure*}

Network telescopes, or darknets, consist of IPv4 address space that receives, but does not respond to, unsolicited Internet traffic via routes announced through the Border Gateway Protocol (BGP).
Researchers have studied this unidirectional traffic to understand its mixtures and origins using darknets as its instrumentation with foundational work attributing its causes to Internet-wide activity that includes
malicious scanning~\cite{2024griffioen,2015dainotti,2017antonakakis,2023bischof,2014durumeric}, 
residual backscatter from DoS attacks~\cite{2014rossow,2017jonker,2017blenn,2021griffioen,2023nawrocki,2024hiesgen}, 
Internet outages~\cite{2011dainotti,2013benson,2012dainotti,2021padmanabhan}, 
and non-trivial network misconfigurations~\cite{2015benson}.

Large-scale empirical studies have characterized darknet-traffic composition and its changes over the past decades. 
In 2004, Pang et al.~\cite{2004pang} was the first to conduct a systematic analysis of darknet traffic\footnote{Pang et al. used a /8, two /19, and ten /24 sized darknets.} in terms of its activities and source, 
followed by a study in 2010 by Wustrow et al.~\cite{2010wustrow} that found traffic volumes\footnote{Wustrow et al. used five different /8 darknets.} 
had grown nearly four-fold along with a reversal in SYN/SYN-ACK trends in the years since. 
Later in 2014, following the release of high-speed scanning tools (ZMap~\cite{2013durumeric} and Masscan~\cite{masscan}), 
Durumeric et al.~\cite{2014durumeric} report\footnote{Durumeric et al. used a darknet roughly the size of a /9.} that horizontal-scans have become common with most malicious scans originating from bullet-proof hosting providers. 
More recently in 2024, Griffioen et al.~\cite{2024griffioen} conduct a 10-year longitudinal study and find a 30-fold increase, which roughly mirrors the trend pictured in Figure~\ref{fig:traffic_growth} for UCSD-NT, 
in scan traffic\footnote{Griffioen et al. use their /16 darknet to draw comparisons.} whose sources rapidly change geographic locations and port targets.
Parallel to this line of work, IPv4 address space exhaustion pressures have led researchers to study darknet traffic collected at non-traditional vantage points 
at IXPs~\cite{2023wagner}, CDNs~\cite{2019richter}, and cloud infrastructure~\cite{2023pauley} though the characteristics of this traffic remains to be extensively compared against traditional darknet traffic.

Despite the evolution of darknet traffic and instrumentation for its collection, researchers continue to devise methods and empirically demonstrate their effectiveness at detecting the various kinds of Internet-wide activities known to occur.
Our survey reviews the design, implementation, and assessments of these methods with an emphasis on those motivated by recent interest in the application of modern machine-learning based approaches to analyze darknet traffic.
% Early studies focused on characterizing the composition of traffic and often uncover patterns that inform detection approaches.
% % Yegneswaran et al.~\cite{2004yegneswaran} quantified the volume of traffic and distributions of senders responsible for originating malicious scans, 
% % subsequently constructing estimates that 25 billion Internet-wide scans originate per day.
% Bellovin~\cite{1993bellovin} earliest published report on the type of packets received by their unused address spaces.
% Pang et al.~\cite{2004pang} later offered the first systematic characterization of darknet traffic composition, including protocol- and application-level breakdowns and analyses of packet content.
% Wustrow et al.~\cite{2010wustrow} provide a follow-up characterization six years later, showed that while absolute traffic volumes had grown substantially, several structural properties—such as port distributions and temporal patterns—remained stable over time.
% Later efforts direct their analysis to specific phenomena: 
% Casado et al.~\cite{2005casado} examined the network-level behavior of scanning worms; 
% others used darknets as passive vantage points for identifying internet outages and routing instabilities~\cite{2011dainotti,2013benson,2015benson,2012dainotti,2021padmanabhan}.

\label{sec:methods}
\section{Methodologies for detecting darknet scanning events}

In this section, we provide a broad survey of the methods that have been proposed to detect scanning activity in darknet traffic. 
To construct the body of works for this survey, we selected only those that assessed their method on real-world traffic.
We review 20 works from the past 10 years (summarized in Table~\ref{tab:methodologies}), organized based on the key technique(s) their detection methods employ.
In addition, we describe several additional components of each method's design that we briefly discuss before elaborating on individual works.

\begin{comment}
% A portion of darknet traffic mixtures results from scans that probe the space of Internet addresses, oftentimes targeting application-layer ports.
% Detection of these scans involves identifying their sources and targets through analysis of behavioral patterns, thereby enabling further inference and/or classification of their intent.
% This section provides a survey of the methodologies proposed for detecting scanning activities in darknet traffic. 
% In this section, we provide a broad survey of the methods that have been proposed for the detection of scanning activity from darknet traffic. 
% We review 20 works from the past 10 years (summarized in Table~\ref{tab:methodologies}) and organize their proposed methods based on general detection task they perform.
% We briefly discuss components of each methodology's design, which include: features of darknet traffic they ingest, traffic representations these features are transformed into, and the general techniques and specific algorithms that operate on such traffic representations to achieve their detection task.
\end{comment}

\begin{comment}
% In this section, we provide a broad survey of existing methodologies that have been proposed for detecting darknet activities and 
% organize prior works into a taxonomy that identifies the need for a systematic evaluation approach to account for the diversity of methods.
% We structure our survey by categorizing detection methodologies primarily based on the type of darknet activity they aim to detect. 
% Within these categories, we review and emphasize two important aspects of each methodology: 
% 1) the class(es) of general \textit{techniques} they employ for detection; and 
% 2) their definition(s) of an \textit{event} belonging under their broader type of targeted activity.
% We briefly discuss these aspects before discussing the methodologies that comprise our taxonomy as shown in Figure~\ref{fig:taxonomy}.

% Our survey structure consists of a top-level categorization of detection methodologies based on the broad class of (i) darknet activity they aim to detect.
% Under these categories, we group similar methods by the (ii) general classes of techniques they employ to achieve their (iii) detection objectives.
% Using these groupings, we summarize the intuition behind each method and elaborate on finer-grained details pertaining to their specific (iv) algorithms and (v) traffic features.
% Here, we briefly discuss components of the methods we survey.

% We structure our survey by categorizing detection methodologies primarily based on the type of darknet activity they aim to detect. 
% Within these categories, we review and emphasize two important aspects of each methodology: 
% 1) the class(es) of general \textit{techniques} they employ for detection; and 
% 2) their definition(s) of an \textit{event} belonging under their broader type of targeted activity.
% We briefly discuss these aspects before discussing the methodologies that comprise our taxonomy as shown in Figure~\ref{fig:taxonomy}.
\end{comment}

\begin{table}[t]
    \small
    \centering
    \caption{Characteristics of event detection methodologies}
    \label{tab:methodologies}
    \renewcommand{\arraystretch}{1.1}
    \setlength{\tabcolsep}{3pt} 
    \begin{tabular}{l p{3cm} ccccccc p{3.5cm} cccc}
        \toprule
        \textbf{Work} &
        \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Detection}\\\textbf{Tasks}\end{tabular}} &
        \multicolumn{7}{c}{\textbf{Techniques}} &
        \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Traffic}\\\textbf{Features}\end{tabular}} &
        \multicolumn{4}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Traffic Repre-}\\\textbf{sentations}\end{tabular}} \\
        \cmidrule(lr){2-2}\cmidrule(lr){3-9}\cmidrule(lr){10-10}\cmidrule(lr){11-14}
        % second header row (leave non-grouped columns blank)
        & &
        \rot{90}{Clustering} & \rot{90}{Dim. Reduction} & \rot{90}{Forecasting} &
        \rot{90}{Thresholding} & \rot{90}{Fingerprinting} & \rot{90}{Rep. Learning} &
        \rot{90}{Pattern Mining} &
        &
        \rot{90}{Graph} & \rot{90}{Feature Vector} & \rot{90}{Sequences} & \rot{90}{Time Series} \\
        \midrule

        2025 Abduaziz et al.~\cite{2025abduaziz} 
        & Source Categorization 
        & \cmark & \cmark & & & & \cmark & 
        & Per-sIP: <\textit{seq(dport)}>
        & & & \cmark & \\

        2024 Gao et al.~\cite{2024gao}
        & Target Identification 
        & & \cmark & & \cmark & & & 
        & Per-dPort: \textit{cnt(pkt), uniq(saddr)}
        & & & & \cmark \\

        2023 Kartsioukas et al.~\cite{2023kartsioukas}
        & Target Identification 
        & & \cmark & & \cmark & & & 
        & Per-dPort: \textit{cnt(pkt), uniq(saddr)}
        & & & & \cmark \\

        2023 Zakroum et al.~\cite{2023zakroum}
        & Source Categorization  
        & \cmark & & \cmark & & & & 
        & 
        & & & & \cmark \\

        2022 Kallitsis et al.~\cite{2022kallitsis}
        & Source Categorization 
        & \cmark & \cmark & & \cmark & & &
        & 
        & & \cmark & & \\

        2022 Zakroum et al.~\cite{2022zakroum} 
        & Target Identification 
        & \cmark & & \cmark & & & & 
        & 
        & & & & \cmark \\

        2021 Tanaka et al.~\cite{2021tanaka}
        & Source
        & \cmark & & & & \cmark & & 
        & 
        & & & & \\

        2021 Han et al.~\cite{2021han}
        & Source and Target Identif. 
        & & \cmark & & & & & 
        & Per-sIP: 
        & & & & \cmark \\

        2021 Gioacchini et al.~\cite{2021gioacchini}  
        & Source Categorization 
        & \cmark & \cmark & & & & &
        & Per-TCP dport: \textit{saddr}
        & & & \cmark & \\

        2020 Griffioen et al.~\cite{2020griffioen}
        & Source Categorization 
        & \cmark & & & & \cmark & &
        & Per-TCP dport: \textit{saddr}
        & & & & \\

        2020 Cohen et al.~\cite{2020cohen}       
        & Source and Target Identif. 
        & & \cmark & & & & & 
        & Per-sIP: \textit{TCP dport}
        & & & & \cmark \\

        2020 Han et al.~\cite{2020han}       
        & Source and Target Identif. 
        & & \cmark & & & & & 
        & s16->nt: <\textit{pktcnt}>
        & & & & \cmark \\
        
        2020 Torabi et al.~\cite{2020torabi}      
        &  
        & & & & & & & \cmark 
        & Per-Flow: \textit{dports, protocol, TTL, TCP flags, IP length, packet count}
        & \cmark & \cmark & & \\

        2020 Soro et al.~\cite{2020soro}   
        & Source Categorization 
        & \cmark & & & & & &
        & Per-sAS,dport: \textit{packet count}
        & & \cmark & & \\
        
        2019 Evrard et al.~\cite{2019evrard}
        & Source Categorization 
        & \cmark & & & & & & 
        & Per-saddr: \textit{TCP dports}
        & \cmark & & & \\
        
        2019 Iglesias et al.~\cite{2019iglesias}    
        & Source Categorization 
        & \cmark & & & & \cmark & & 
        & Per-saddr: \textit{22 total features}
        & & \cmark & & \\

        2019 Niranjana et al.~\cite{2019niranjana} 
        & Sender Classification 
        & \cmark & & & & & & 
        & Per-
        & & \cmark & & \\

        2019 Kanehara et al.~\cite{2019kanehara}    
        & Source and Target Identif. 
        & & \cmark & & & \cmark & & 
        & Per-sIP,dPort: \textit{ts, pktcnt}
        & & & & \cmark \\
        
        2017 Lagraa et al.~\cite{2017lagraa}
        & Source Identification 
        & \cmark & & & & & &
        & \textit{}
        & \cmark & & & \\
        
        2016 Ban et al.~\cite{2016ban}
        & Source Identification 
        & & \cmark & & & & & 
        & \textit{saddr, dport,}
        & 
        & & \cmark & \cmark \\

        2015 Nishikaze et al.~\cite{2015nishikaze}
        & Source Categorization 
        & \cmark & & & & & & 
        & saddr16: \textit{pktcnt, sport, dport, daddr, scantype}
        & & \cmark & & \\

        \bottomrule
    \end{tabular}
\end{table}


% \begin{table}[t]
%     \scriptsize
%     \caption{Characteristics of event detection methodologies}
%     \label{tab:methodologies}
%     \setlength{\tabcolsep}{2pt} 
%     \begin{tabular}{l cccc p{1.8cm} cccccc cccc p{1.8cm}}
%         \toprule
%         \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Work}}} & 
%         \multicolumn{4}{c}{\textbf{Activities}} & 
%         \multicolumn{1}{c}{\textbf{Detection Tasks}} &
%         \multicolumn{6}{c}{\textbf{Techniques}} & 
%         \multicolumn{4}{c}{\textbf{Traffic Representations}} & 
%         \multicolumn{1}{c}{\textbf{Traffic Features}} \\
%         \cline{2-5}  \cline{7-12} \cline{13-16} 
        
%         & \rot{90}{Scanning} & \rot{90}{DDoS} & \rot{90}{Outage} & \rot{90}{Misconfig.} 
%         & & \rot{90}{Clustering} & \rot{90}{Dim. Reduction} & \rot{90}{Forecasting} 
%         & \rot{90}{Threshold/Fingerprint} 
%         & \rot{90}{Rep. Learning} 
%         & \rot{90}{Pattern Mining} 
%         & \rot{90}{Graph} & \rot{90}{Feature Vector} & \rot{90}{Sequences} & \rot{90}{Time Series} & \\ 
%         \midrule

%         2025 Abduaziz et al.~\cite{2025} & $\checkmark$ & & & & & $\checkmark$ & $\checkmark$ & & & & & & & $\checkmark$ & & \\

%         2024 Enyanet et al.~\cite{2024enyanet} & & & $\checkmark$ & $\checkmark$ & & $\checkmark$ & & $\checkmark$ & & & & & & & $\checkmark$ & \\

%         2023 Kartsioukas et al.~\cite{2023kartsioukas} & $\checkmark$ & $\checkmark$ & & & & & $\checkmark$ & & $\checkmark$ & & & & & & $\checkmark$ & \\

%         2023 Tanaka et al.~\cite{2023tanaka,2021tanaka} & $\checkmark$ & & & & & & & & & & & $\checkmark$ & $\checkmark$ & $\checkmark$ & & \\

%         2023 Zakroum et al. (B)~\cite{2023zakroum} & $\checkmark$ & & & & & $\checkmark$ & & $\checkmark$ & & & & & & & $\checkmark$ & \\

%         2022 Kallitsis et al.~\cite{2022kallitsis} & $\checkmark$ & $\checkmark$ & & & & $\checkmark$ & $\checkmark$ & & $\checkmark$ & & & & $\checkmark$ & & & \\

%         2022 Zakroum et al. (A)~\cite{2022zakroum,2018zakroum} & $\checkmark$ & & & & & $\checkmark$ & & $\checkmark$ & & & & & & & $\checkmark$ & \\

%         2021 Han et al.~\cite{2021han,2022han} & $\checkmark$ & & & & & & $\checkmark$ & & & & & & & & $\checkmark$ & \\

%         2021 Gioacchini et al.~\cite{2021gioacchini,2023gioacchini} & $\checkmark$ & & & & & $\checkmark$ & $\checkmark$ & & & & & & & $\checkmark$ & & \\

%         2020 Han et al.~\cite{2020han,2022han} & $\checkmark$ & & $\checkmark$ & $\checkmark$ & & & $\checkmark$ & & & & & & & & $\checkmark$ & \\

%         2020 Torabi et al.~\cite{2020torabi,2018torabi} & $\checkmark$ & & & & & & & & & & & $\checkmark$ & $\checkmark$ & & & \\

%         2020 Soro et al.~\cite{2020soro} & $\checkmark$ & & & & & $\checkmark$ & & & & & & & & $\checkmark$ & & \\

%         2019 Evrard et al.~\cite{2019evrard} & $\checkmark$ & & & & & $\checkmark$ & & & & & & $\checkmark$ & & & & \\

%         2019 Iglesias et al.~\cite{2019iglesias} & $\checkmark$ & $\checkmark$ & & & & $\checkmark$ & & & $\checkmark$ & & & & $\checkmark$ & & & \\

%         2019 Niranjana et al.~\cite{2019niranjana} & $\checkmark$ & & & & & $\checkmark$ & $\checkmark$ & & & & & $\checkmark$ & $\checkmark$ & $\checkmark$ & & \\

%         2019 Cabana et al.~\cite{2019cabana} & $\checkmark$ & & & & & $\checkmark$ & & & $\checkmark$ & & & $\checkmark$ & $\checkmark$ & & & \\

%         2019 Kanehara et al.~\cite{2019kanehara,2022han} & $\checkmark$ & & & & & & $\checkmark$ & & $\checkmark$ & & & & & & $\checkmark$ & \\

%         2019 Guillot et al.~\cite{2019guillot} & & & $\checkmark$ & $\checkmark$ & & $\checkmark$ & & $\checkmark$ & & & & & & & $\checkmark$ & \\

%         2018 Shaikh et al.~\cite{2018shaikh} & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & & & & & & & & & $\checkmark$ & & & \\

%         2017 Lagraa et al.~\cite{2017lagraa,2019lagraa} & $\checkmark$ & & & & & $\checkmark$ & & & & & & $\checkmark$ & & & & \\

%         2016 Ban et al.~\cite{2016ban} & $\checkmark$ & & & & & & $\checkmark$ & & & & & & & $\checkmark$ & $\checkmark$ & \\ 

%         2015 Nishikaze et al.~\cite{2015nishikaze} & $\checkmark$ & & & & & $\checkmark$ & & & & & & & $\checkmark$ & & & \\

%         \bottomrule
%     \end{tabular}
% \end{table}

\vspace{0.25em}
\noindent{\textbf{Detection tasks}} refer to three types of objectives generalized from specifically-defined tasks in our surveyed works. 
We define these types based on the \dots.
% involve the identification of either senders of darknet traffic or targets that receive darknet traffic.
\maxnote{Circle back to this, explanation unclear}

% \vspace{0.25em}
% \noindent{\textbf{Class(es) of activity}} correspond to the canonical activities observed in darknet traffic as described in Section~\ref{sec:bg}. 
% For each study, we identify which class(es) they target based on explicitly stated analysis goals of each methodology and the empirical findings reported from their assessments.
% Some methods such as~\cite{2022kallitsis,2019iglesias} are capable of targeting multiple types of activities since traffic dynamics associated with scanning, backscatter, and misconfiguration can overlap. 
% In practice, studies such as~\cite{2019evrard} filter traffic inputs using heuristics (e.g., flags indicating TCP response traffic~\cite{2006moore}, likely-spoofed sender IP addresses~\cite{2015dainotti}) to ensure their methodology analyzes a specific type of activity.

% \vspace{0.25em}
% \noindent{\textbf{Event Definitions}} refers to attributes represented in the outputs of a given framework.
% These attributes derive from packet header fields and implicitly define an instance of a broader type of event.
% For example, a framework may define a scanning event using a source-based schema that consists of a timestamp, source IP address, an assigned cluster, and a cluster flag indicating potential malicious intent.

\vspace{0.25em}
\noindent{\textbf{Technique(s)}} differentiate functionalities undertaken by specific \textbf{algorithms(s)} within the scope of each methodology. 
Across our surveyed works, we identified 7 classes of techniques which include 
\textit{dimensionality reduction},
\textit{clustering},
\textit{forecasting},
\textit{thresholding},
\textit{representation learning},
\textit{frequent pattern mining},
and \textit{fingerprinting}.
Most methodologies employ a combination of techniques 
(\textit{e.g.}, dimensionality reduction as a prior step to clustering or thresholding similarity metrics computed from intermediary representations)
to accomplish analysis subtasks.

\vspace{0.25em}
\noindent{\textbf{Traffic features and representations.}} 
Methods consist of a preprocessing step that parses properties of raw darknet traffic into representations usable by their algorithms.
Depending on the method's detection task, traffic features are defined per-source, per-target, or per-flow at different levels of aggregation
and encoded as one of the four main types of representations: \textit{graphs}, \textit{feature vectors}, \textit{sequences}, \textit{time series}.

\subsection{Graph-mining methods}
Graph-based methods operate on models of sender-destination interactions extracted from darknet traffic.
To identify similar scanning behaviors, \textit{i.e.}, horizontal or vertical scanners, these methods apply clustering and thresholding techniques to predefined graph formulations.
Lagraa et al.~\cite{2017lagraa,2019lagraa} and Evrard et al.~\cite{2019evrard} model TCP traffic as unipartite graphs (nodes and edges represent respectively ports and consecutive port scans from the same sender) aggregated from per-sender port scans.
To extract similar probed ports, both apply thresholding graph metrics (shortest-path similarity in ~\cite{2019evrard}, node centrality in ~\cite{2017lagraa}).
In follow-up work, Lagraa et al.~\cite{2019lagraa} provide an additional graph definition to detect horizontal scanners (nodes redefined as darknet destination addresses probed on the same port) and employ an alternative clustering algorithm which uses graph modularity as a metric.
Soro et al.~\cite{2020soro} construct weighted bipartite graphs that represent TCP scan traffic sent between source Autonomous Systems (ASes) and destination ports. 
Using the Greedy Modularity Algorithm, they extract groups of ASes that target similar sets of ports associated with vulnerable applications.

% Despite their straightforward design, 
% - typically used for exploratory analyses
% - no direct comparisons 

% source Autonomous Systems (ASes) to destination ports based on the number of packets in TCP scan traffic that ASes send and extract ASes that target similar sets of ports using the Greedy Modularity Algorithm.
% Evrard et al.~\cite{2019evrard} and Lagraa et al.~\cite{2017lagraa,2019lagraa} represent TCP scan traffic as unipartite graphs, where nodes represent ports and edges represent consecutive port scans, respectively on a global- and individual sender IP-basis. 
% To extract similarly probed ports, Evrard et al.~\cite{2019evrard} threshold a shortest-path similarity metric while Lagraa et al.~\cite{2017lagraa} instead threshold node centrality measures, such as degree centrality and betweenness measure, applied to a unified scan-graph.
% To extract similarly probed ports, Evrard et al.~\cite{2019evrard} threshold a shortest-path similarity metric while Lagraa et al.~\cite{2017lagraa} instead threshold node centrality measures, such as degree centrality and betweenness measure, applied to a unified scan-graph.
% In follow-up work, Lagraa et al.~\cite{2019lagraa} provide an additional graph definition aimed to detect horizontal scanners by redefining nodes as darknet destination addresses probed on the same port and employ an alternative clustering metric that measures graph modularity.

% \noindent{\textbf{Sender Classification}}
\subsection{Representation learning methods}
Representation learning techniques play a key role in modern machine-learning.
Given a dataset, their algorithms have the capability to automatically learn a lower-dimensional representation of raw data for downstream modeling tasks.

Beginning in 2020 with the Word2Vec~\cite{2013mikolov} algorithm, researchers began devising methodologies that incorporated these techniques into darknet traffic analysis.
Cohen et al.~\cite{2020cohen} proposed \textit{Dante} which leveraged this algorithm to map \textit{sequences of ports} targeted by individual senders of darknet traffic into lower-dimensional vector spaces for subsequent application of unsupervised clustering techniques.
Gioacchini et al.~\cite{2021gioacchini} later proposed \textit{DarkVec} which in contrast to \textit{Dante}, uses Word2Vec to map \textit{sequences of senders} that arrive at grouped destination ports. 
In their follow-up work~\cite{2023gioacchini}, \textit{i-DarkVec}, Gioacchini et al. improve their previous methodology by scaling to larger volumes of traffic. 
Abduaziz et al.~\cite{2025abduaziz} replicate \textit{Dante}'s embedding generation step and instead apply semi-supervised clustering techniques.

From 2022 onward, more sophisticated representation learning methods emerged.
Compared to Word2Vec-based methods, these ingest larger numbers of darknet traffic features, relying on more complex algorithms and neural-network architectures to achieve their detection tasks.
Using a set of 12 features to profile darknet traffic sources, 
Kallitsis et al.~\cite{2022kallitsis}'s method employs an autoencoder neural network architecture to map senders into lower-dimensional vector spaces.
Results of their comparison against \textit{DarkVec} showed that their method more accurately clustered labeled senders of classes.

% Zakroum et al.~\cite{2023zakroum} 
% ~\cite{2022zakroum}

% Gioacchini et al.~\cite{2021gioacchini,2023gioacchini} propose a domain-specific adaptation of Word2Vec to embed senders based on their order of arrival from packet sequences \maxnote{defined over variations of port combinations}.
% Kallitsis et al.~\cite{2022kallitsis} include a more comprehensive set of features to train autoencoders and subsequently cluster sender embeddings of a lower-dimensional space. 
% Nishikaze et al.~\cite{2015nishikaze} cluster feature vectors that represent source /16 subnets and 27 selected features.
% Zakroum et al.~\cite{2023zakroum} 

% \vspace{0.25em}
% \noindent{\textbf{Time Series Dimensionality Reduction Methods}}
\subsection{Time series-based methods}
Time series representations offer an aggregated view of darknet traffic that supports analysis by a variety of techniques.
Their methods typically operate on a large space of inputs with the goal of localizing time periods that correspond 
to abnormal traffic activity, defined per-method. 
Several methods achieve this via dimensionality reduction techniques. \maxnote{discuss scalability limitations}
In 2019, Kanehara et al.~\cite{2019kanehara} applied Nonnegative Tucker Decomposition (NTD)~\cite{2015zhou} to packet count time series between senders and destination ports they contacted.
Their findings from real-world traffic analysis identified groups of behaviorally-similar senders on several ports of applications containing known vulnerabilities.
Han et al. proposed \textit{DarkNMF}~\cite{2021han} and \textit{DarkGLASSO}~\cite{2020han}, which respectively apply Nonnegative Matrix Factorization (NMF)~\cite{2000lee} and Graphical LASSO~\cite{2008friedman} to 
time series of packet counts per source host (for \textit{DarkNMF}, also per destination port).
Kartsioukas et al.~\cite{2023kartsioukas} apply Incremental Principal Component Analysis (iPCA)~\cite{2012arora} to time series of unique senders per TCP, UDP ports and ICMP.

% In 2023, the same authors 

% Methods that are well-suited for detecting anomalous traffic that targets specific ports or arrives from coordinated groups of senders.
% Han et al.~\cite{2020han,2021han}, Kanehara et al.~\cite{2019kanehara}, and Kartsioukas et al.~\cite{2023kartsioukas} employ classic dimensionality reduction techniques, specifically on time-series representations of darknet traffic, 
% alongside ad-hoc thresholding techniques to identify timeframes containing sources of coordinated scanning or targeted services by their ports.
% These techniques include algorithms such as Non-negative matrix factorization (NMF)~\cite{2000lee}, Non-negative tucker-decomposition (NTD)~\cite{2015zhou}, and  Incremental Principal Component Analysis (i-PCA)~\cite{2012arora}, 
% each of which reduce the space of potential source and destination tuples by filtering for those whose time series possess high reconstruction errors. 
% Graphical LASSO~\cite{2008friedman} instead focuses solely on sources by identifying non-trivial correlations in TCP-SYN packet volumes sent by source /16 subnetworks.

\subsection{Fingerprinting methods}

Fingerprinting methods operate on information embedded in packet headers of darknet traffic. 
The key intuition behind the use of these methods are that distributed yet coordinated hosts likely employ the same 
stateless scanning tools, \textit{e.g.}, ZMap~\cite{2013durumeric}, embed identifying information in 
the same parts of a packet which can be used to infer their fingerprints.
Griffioen et al.~\cite{2020griffioen} first proposed this technique which enabled correlation of similar hosts suspected 
to use the same scanning tools.
Tanaka et al.~\cite{2021tanaka,2023tanaka} extend Griffioen et al.'s method to generate candidate fingerprints from a 
larger set of header fields using a genetic algorithm.


% Nishikaze et al.~\cite{2015nishikaze}
% Torabi et al.~\cite{2020torabi}

% \label{sec:methods:dos}
% \subsection{Backscatter Detection}
% Several of the previously mentioned methodologies in Section~\ref{sec:methods:scan} detect both scans and backscatter since reflected response traffic generated by spoofed DoS attacks can resemble scanning behavior, e.g., a DoS victim's response to spoofed traffic compared to high-volume horizontal scans.
% While distinguishing backscatter from scans in stateful protocol traffic such as TCP, e.g., by inspecting untampered TCP flags, for stateless protocols such as ICMP and UDP it is less so. 
% \maxnote{enumerate works here}

% \label{sec:methods:outage}
% \subsection{Outage Detection}
% In contrast to scanning and backscatter detection, outage detection methodologies aim to identify the absence of expected traffic.
% These methodologies frame detection in terms of traffic sources defined at varying spatial grains (e.g., per-subnet, per-AS, or per-country) which may depend on darknet-exogenous data for geolocation or AS-organization lookups.

% Our survey identifies two works that propose complete outage detection methodologies.
% Guillot et al. propose Chocolatine~\cite{2019guillot} which forecasts the expected number of unique senders aggregated at per-AS and per-country granularities by training a Seasonal Autoregressive Integrated Moving Average (SARIMA) model over historical sender counts of unfiltered, protocol-agnostic traffic inputs; 
% sender counts beyond specified 5-minute prediction thresholds are flagged as potential outages.
% Enyanet et al. propose Durbin~\cite{2024enyanet} which leverages a Bayesian approach for inferring outages down to a coarser spatial grain of a /24 subnetwork in comparison to Chocolatine. Furthermore, Durbin optimizes parameters per-subnet and and claims to more flexibly exploit space-time precision trade-offs by doing so. 

% \begin{table}[t]
%     \small
%     \caption{Taxonomy of Detection Methodologies }
%     \label{tab:frameworks-noalgos}
%     \begin{tabular}{llllc}
%         \toprule
%         \multicolumn{1}{c}{Work} & \multicolumn{4}{c}{Framework} \\
%         \midrule
%         & \rot{45}{i. Activity} & \rot{45}{ii. Technique(s)} & \rot{45}{\begin{tabular}[c]{@{}l@{}}iv. Traffic\\ Rep.\end{tabular}} & \rot{45}{\begin{tabular}[c]{@{}l@{}}v. Output\\ Attributes\end{tabular}} \\
%         \midrule

%         Evrard et al.~\cite{2019evrard} &
%         \markX &
%         \markB &
%         \markD &
%         Dst. Port \\

%         Lagraa et al.~\cite{2017lagraa,2019lagraa} &
%         \markX &
%         \markB &
%         \markD &
%         Dst. Port \\

%         Kallitsis et al.~\cite{2022kallitsis} &
%         \markX\markY &
%         \markI\markA\markB &
%         \markE &
%         Src. IP \\

%         Iglesias et al.~\cite{2019iglesias} &
%         \markX\markY &
%         \markB\markH &
%         \markE &
%         Src. IP \\

%         Nishikaze et al.~\cite{2015nishikaze} &
%         \markX &
%         \markB &
%         \markE &
%         Src. /16 \\

%         Soro et al.~\cite{2020soro} &
%         \markX &
%         \markB &
%         \markF &
%         Src. AS \\

%         Gioacchini et al.~\cite{2021gioacchini,2023gioacchini} &
%         \markX &
%         \markA\markB &
%         \markF &
%         Src. IP \\

%         Abduaziz et al.~\cite{2025} &
%         \markX &
%         \markA\markB &
%         \markF &
%         Src. IP \\

%         Han et al.~\cite{2021han,2022han} &
%         \markX &
%         \markA &
%         \markG &
%         Src. /16, Dst. Port \\

%         Han et al.~\cite{2020han,2022han} &
%         \markX\markEtc &
%         \markA &
%         \markG &
%         Src. /16 \\

%         Kanehara et al.~\cite{2019kanehara,2022han} &
%         \markX &
%         \markA\markH &
%         \markG &
%         Src. /16, Dst. Port \\


%         Kartsioukas et al.~\cite{2023kartsioukas} & 
%         \markX\markY & 
%         \markA\markH & 
%         \markG & 
%         \textit{TODO} \\

%         Ban et al.~\cite{2016ban} & 
%         \markX & 
%         \markA & 
%         \markF\markG & 
%         Dst. Port \\ 

%         Torabi et al.~\cite{2020torabi,2018torabi} &
%         \markX &
%         \markJ &
%         \markD,\markE &
%         \textit{TODO} \\

%         Tanaka et al.~\cite{2023tanaka,2021tanaka} &
%         \markX &
%         \textit{TODO} &
%         Source &
%         \textit{TODO} \\

%         Niranjana et al.~\cite{2019niranjana} &
%         \markX &
%         \markA\markB &
%         Source &
%         \textit{TODO} \\

%         Cabana et al.~\cite{2019cabana} &
%         \markX &
%         \markB\markH &
%         \markD\markE &
%         \textit{TODO} \\

%         Shaikh et al.~\cite{2018shaikh} &
%         \markX\markY\markZ\markEtc &
%         \textit{TODO} &
%         \markE &
%         \textit{TODO} \\
  
%         Zakroum et al.~\cite{2022zakroum,2018zakroum} &
%         \markX &
%         \markC\markB &
%         \markG &
%         Dst. Port \\

%         Zakroum et al.~\cite{2023zakroum} &
%         \markX &
%         \markC\markB &
%         \markG &
%         Dst. Port \\

%         Guillot et al.~\cite{2019guillot} &
%         \markZ&
%         \markC\markB &
%         \markG &
%         Dst. Port \\

%         Enyanet et al.~\cite{2024enyanet} &
%         \markZ &
%         \markC\markB &
%         \markG &
%         Dst. Port \\

%         Zakroum et al.~\cite{2023zakroum} &
%         \markX &
%         \markC\markB &
%         \markG &
%         Dst. Port \\

%         Guillot et al.~\cite{2019guillot} &
%         \markZ&
%         \markC\markB &
%         \markG &
%         Dst. Port \\

%         Enyanet et al.~\cite{2024enyanet} &
%         \markZ &
%         \markC\markB &
%         \markG &
%         Dst. Port \\

%         \bottomrule
%     \end{tabular}

%     \vspace{2pt}
%     \parbox{\linewidth}{\raggedright
%         \textit{Activities:} \markX~Scanning, \markY~DDoS, \markZ~Outage, \markEtc~Misconfiguration.\\
%         \textit{Techniques:} \markA~Dimensionality Reduction, \markB~Clustering, \markC~Forecasting, \markH~Thresholding, \markI~Representation Learning, \markJ~Frequent Pattern Mining, \markH~Fingerprinting.\\
%         \textit{Traffic representation:} \markD~Graph, \markE~Feature Vector, \markF~Sequences, \markG~Time Series.
%     }
% \end{table}

\label{sec:assessments}
\section{Empirical Assessments of Detection Methodologies}

\begin{table*}[t!]
    \small
    \setlength{\tabcolsep}{2.5pt}
    \caption{
        Details of method assessments found in our surveyed works. 
        Multiple citations per entry indicate groups of highly similar works; assessment details reflect bolded citations.
        Table~\ref{tab:telescopes} lists additional details of telescopes referenced in this table.
    }
    \label{tab:eval}
    \begin{tabular}{@{}lcccccccccc@{}}
        \toprule
        & \multicolumn{3}{c}{\bf Replicability} 
        & \multicolumn{5}{c}{\bf Dataset Attributes} 
        & \multicolumn{1}{c}{\textbf{Compar-}}
        & \multicolumn{1}{c}{\textbf{Labels}} \\
        \cmidrule(lr){2-4} \cmidrule(lr){5-9}
        \textbf{Work} 
        & \textbf{Code} & \textbf{Specs} & \textbf{Data}
        & \textbf{Telescope(s)} & \textbf{Duration} & \textbf{Year} & \textbf{Packets} & \textbf{Bytes} 
        & \textbf{ison} 
        & \textbf{Labels} \\
        \midrule

        Abduaziz et al.~\cite{2025abduaziz}
        &  & \cmark & ---
        & NT-1,3
        & 7D,10D & 2022,2023
        & --- & 1.18, 7.61GB
        & \cite{2020cohen}
        & A3,A3 \\

        Kartsioukas et al.~\cite{2023kartsioukas}
        &  &  & ---
        & NT-2
        & 1M & 2016
        & --- & ---
        & \cite{2004lakhina}
        & \cmark \\

        Zakroum et al.~\cite{2023zakroum}
        &  &  & ---
        & NT-3,6
        & 4.5Y & 2018
        & --- & ---
        & \cite{2023zakroum}
        & A3 \\

        Kallitsis et al.~\cite{2022kallitsis}
        & \cmark & \cmark & ---
        & NT-2
        & 28D, 1D & 2016,2022
        & 49B, 3.1B & ---
        & \cite{2021gioacchini}
        & A3 \\

        Zakroum et al.\textbf{~\cite{2022zakroum}}~\cite{2018zakroum}
        &  & \cmark & ---
        & NT-3,6
        & 3.5Y & 2017
        & --- & $1.5+\mathrm{TB}$
        & \cite{2018zakroum}
        & A2 \\

        Han et al.\textbf{~\cite{2021han}}~\cite{2022han}
        & \cmark &  & ---
        & NT-3
        & 1M & 2018
        & --- & ---
        & \cite{2020han,2006takeuchi,2019kanehara}
        & A3 \\

        Gioacchini et al.\textbf{~\cite{2021gioacchini}}~\cite{2023gioacchini}
        & \cmark & \cmark & ---
        & NT-4
        & 30D & 2021
        & 63M & ---
        & \cite{2020cohen,2017ring}
        & A3, A3 \\

        Cohen et al.\textbf{~\cite{2020cohen}}
        & & & ---
        & NT-4
        & 30D & 2021
        & 63M & ---
        & \cite{2020cohen,2017ring}
        & A3, A3 \\

        Han et al.\textbf{~\cite{2020han}}~\cite{2022han}
        & \cmark & \cmark & ---
        & NT-3
        & 1M & 2018
        & --- & ---
        & \cite{2006takeuchi}
        & A1 \\

        Torabi et al.~\cite{2020torabi}
        & \cmark & \cmark & ---
        & 
        & & 
        & --- & ---
        & 
        & \\

        Soro et al.~\cite{2020soro}
        &  &  & ---
        & NT-4,5
        & 3W,1D & 2020
        & --- & ---
        & 
        & A2 \\

        Evrard et al.~\cite{2019evrard}
        &  &  & ---
        & NT-3,6
        & 9M & 2015
        & 8M & ---
        & 
        & A1 \\

        Iglesias et al.~\cite{2019iglesias}
        &  & \cmark & ---
        & NT-1
        & 6M & 2012
        & --- & 2.1 TB
        & 
        & A1 \\

        Niranjana et al.~\cite{2019niranjana}
        &  &  & ---
        & 
        & & 
        & & ---
        & 
        & \\

        Kanehara et al.\textbf{~\cite{2019kanehara}}~\cite{2022han}
        & \cmark & \cmark & ---
        & NT-3
        & 10M & 2017
        & --- & ---
        & \cite{2021han,2020han,2006takeuchi}
        & A1 \\

        Lagraa et al.\textbf{~\cite{2019lagraa}}~\cite{2017lagraa}
        &  & \cmark & ---
        & NT-6
        & 2Y & 2014
        & 2B & 500 GB
        & 
        & A1 \\

        Bou-Harb et al.\textbf{~\cite{2019bouharb}}~\cite{2015bouharb}
        &  & \cmark & ---
        & NT-1,7
        & 1M,1M & 2016,2014
        & --- & 670, 240GB
        & \cite{2018bouharb}
        & A3 \\

        Ban et al.~\cite{2017ban}
        &  &  & ---
        & NT-3
        & --- & ---
        & --- & ---
        & \cite{2012ban}
        & A2 \\

        Ban et al.~\cite{2016ban}
        &  &  & ---
        & NT-3
        & 1y & 2015
        & $3\times10^{7}$ & ---
        & 
        & A1 \\

        Bou-Harb et al.~\cite{2014bouharb}
        &  &  & ---
        & NT-7
        & 2D & 2013
        & $10^6$ & 30GB
        & 
        & A2 \\

        Nishikaze et al.~\cite{2015nishikaze}
        &  &  & ---
        & NT-3
        & 28D & 2014
        & 303M & ---
        & 
        & A1 \\

        % Guillot et al.~\cite{2019guillot} 
        % & \cmark &
        % & NT-1
        % & 9Y & 2009--2018
        % & --- & ---
        % & \cite{2013quan}
        % & A3 \\

        % Enyanet et al.~\cite{2024enyanet} 
        % & &
        % &
        % & &
        % & &
        % & &
        % \\

        \midrule
        \textbf{Aggregate}
        & 4/16 & 7/16 & ---
        & 8--24
        & 1w--3.5y & 2012--2021
        & --- & ---
        & 7/16
        & --- \\
        \bottomrule
    \end{tabular}
\end{table*}
\begin{table}[t!]
	\small
	\caption{Summary of network telescopes referenced in surveyed works.}\label{tab:telescopes}
	\begin{tabular}{cccc}
		\toprule
		Telescopes & Country & Size & Data availability\\
		\midrule
		\textbf{NT-1.} UCSD-NT~\cite{ucsd-nt} & US & /9+/10 & Raw traces and flow data \\
		\textbf{NT-2.} Merit ORION~\cite{orion-nt} & US & $\sim$7 $\times$/16s & Raw trace, custom-defined event data\\
		\textbf{NT-3.} NICTER~\cite{nicter-nt} & JP &  /17, /18, 2$\times$/20 & TCP SYN only, anonymized flow data\\
		\textbf{NT-4.} Politecnico di Torino \cite{2020soro} & IT & 3 $\times$ /24 & Unknown\\
		\textbf{NT-5.} Darknet-BR \cite{2025camargo} & BR & /19 & Unknown\\
		\textbf{NT-6.} LHS Nancy~\cite{inria-nt} & FR & /20 & Raw trace\\
		\textbf{NT-7.} Farsight~\cite{farsight} & US & /13 & Private\\
		\bottomrule
	\end{tabular}
\end{table}

To demonstrate the utility of their detection methodologies, prior works conduct assessments using real-world darknet traffic datasets.
These assessments and their results provide evidence of a method's performance under realistic settings and offer empirical insights into its detection capabilities and general scalability.
In this section, we characterize prior works along the lines of credibility and reproducibility of their assessments by reviewing:
(i) characteristics of the darknet traffic datasets they use; and
(ii) their approach to validating detection outputs of their methodology.
Furthermore, we consider implementation details of detection methodologies since the reproducibility of assessments and results are closely tied to the availability of method source code and specifications of chosen computational environments.


% \vspace{0.25em}
\subsection{Characteristics of darknet traffic datasets.}

We consider three characteristics of each dataset used in prior work to assess detection methodologies.
These include 1) the timeframe covered by the dataset, 2) the darknet whose traffic comprises the dataset, 3) and the dataset's traffic volume measured in units of packets and bytes.
% For the datasets used in prior works, we consider several characteristics relevant to interpreting method assessment results:
% the timeframe over which traffic was collected, 
% the specific darknet that received this traffic, 
% the size of the darknet's address space, and its traffic volume measured in units of packets and bytes.
% Empirical studies such as~\cite{2025camargo,2019soro} established that address space size has a non-trivial impact on the observability of darknet traffic (\textit{i.e.,} in terms of traffic composition and visibility of sources).

Across our surveyed works, we identified a total of 7 darknets (listed in Table~\ref{tab:telescopes}) from which datasets source their traffic. 
The amount of IPv4 address space occupied by each darknet varies; the largest and smallest sizes respectively span roughly a /9 (approx. 12.5M addresses in NT-1) 
and three /24 networks (768 addresses in NT-4). 
While these numbers represent the most up-to-date sizes reported by operators, darknet address space in practice may fluctuate based on ad-hoc BGP announcements 
(e.g., for leasing purposes~\cite{2025mannel} or in the case of more permanent changes such as address ownership transfers~\cite{2019ardc}). 
Empirical studies such as~\cite{2025camargo,2019soro} show that the size and ranges of IP addresses occupied by a darknet have a non-trivial impact on the observability, i.e., in terms of traffic composition and source visibility) of small-scale scanning events.
% Empirical studies such as~\cite{2025camargo,2019soro} established that address space size has a non-trivial impact on the observability of darknet traffic (\textit{i.e.,} in terms of traffic composition and visibility of sources).
Thus, assessments results may not generalize across datasets sourced from different darknets.

We visualize the combined range of timeframes covered by darknet-traffic datasets from the start of 2012 until late 2023 in Figure~\ref{fig:cov_assess}. 
The proportion of time covered over this range by at least a single dataset (at a daily granularity) sits at 68\%. 
Most datasets are short snapshots: over half of all datasets span fewer than two months, roughly a third cover under three years of darknet traffic, and less than a fifth cover three or more years. 
Since a majority of works do not provide clear rationale for their timeframe selection, we infer that selection is largely opportunistic and based on availability of darknet traffic data at the time of assessment. 

Some exceptions~\cite{2022kallitsis,2023kartsioukas} use known dates of landmark Internet-wide events, \textit{e.g.}, launch of the Mirai botnet, to guide their selection of timeframes. 
In addition to Mirai, Figure 2 plots the start date of 17 additional events (further summarized in Table 5) identified as either major remote execution vulnerabilities or scans originated by botnets. 
While the traffic associated with these events, in theory, should have been observed by darknets, besides~\cite{2022kallitsis,2023kartsioukas} there have been no explicit studies of their detectability in darknet traffic despite 
the fact that all but one of the events are covered by the timeframes of datasets used in assessments.
We further discuss the implication of this finding in Section~\ref{sec:fw}.

% Some exceptions~\cite{2022kallitsis,2023kartsioukas} select specific timeframes centered around landmark Internet-wide events, e.g., the Mirai botnet, for validation purposes (later discussed in Section~\ref{sec:fw}).
% In addition to Mirai, Figure~\ref{fig:cov_assess} plots the start date of X additional events (summarized in Table~\ref{tab:events}), observable in darknet traffic, identified as either major vulnerabilities or scans by botnets.
% While X\% of these events are covered by dataset timeframes, none are mentioned explicitly in surveyed works besides the exceptions previously mentioned which further strengthens our inference. 
% We discuss another implication for future work in Section~\ref{sec:fw}.

% Recompute

% Nonetheless, darknet size directly correlates with traffic volumes and ostensibly more variability in its mixtures; thus the generalizability of method performance is sensitive to 
% larger darknets tend to receive greater and more varied traffic~\cite{@@} 

% \vspace{0.25em}
\mybox{Takeaways and Findings}{green!40}{green!10}{

\textbf{Takeaways:} 
Datasets used throughout method assessments possess different levels of observability in their traffic 
due to the variety of darknets and timeframes they sample.
Generalizability of a specific method's performance on one dataset to another remains unclear. 
}
\begin{table}[ht!]
    \caption{Historic landmark events either purported or confirmed to have been observed by darknets.}
    \label{tab:events}
    \centering
    \begin{tabular}{l c r l : l c r l}
    \hline
    \textbf{ID} & \textbf{Date} & \textbf{Event Name} & \textbf{Type} &
    \textbf{ID} & \textbf{Date} & \textbf{Event Name} & \textbf{Type} \\
    \hline
    I    & 2012-04 & Carna            & Botnet        &
    X     & 2017-10 & Reaper           & Botnet \\
    II   & 2014-03 & Heartbleed       & Remote Exp.   &
    XI    & 2018-05 & VPNFilter        & Botnet \\
    III  & 2014-09 & Shellshock       & Remote Exp.   &
    XII   & 2018-06 & Crackonosh       & Botnet \\
    IV   & 2016-08 & Mirai            & Botnet        &
    XIII  & 2019-05 & BlueKeep         & Remote Exp. \\
    V    & 2017-04 & Eternal Blue     & Remote Exp.   &
    XIV   & 2020-06 & Ripple20         & Remote Exp. \\
    VI   & 2017-05 & WannaCry         & Botnet        &
    XV    & 2020-03 & SMBGhost         & Remote Exp. \\
    VII  & 2017-04 & BrickerBot       & Botnet        &
    XVI   & 2021-12 & Log4JShell       & Remote Exp. \\
    VIII & 2016-03 & Amnesia          & Botnet        &
    XVII  & 2021-06 & PrintNightmare   & Remote Exp. \\
    IX   & 2017-06 & NotPetya         & Botnet        &
          &         &                  &  \\
    \hline
    \end{tabular}
\end{table}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/coverage_graph.pdf}
    \caption{Timeframes and sources of darknet-traffic datasets used in assessments (Section~\ref{sec:assessments}) of detection methodologies, overlapped with dates of Internet-wide events (listed in Table~\ref{tab:events}) observable by darknets.}
    \label{fig:cov_assess}
\end{figure}

% \vspace{0.25em}
% \noindent{\textbf{Validation of detection results.}}
\subsection{Strategies for validating detection results}

Since limited definitive "ground truth" exists for attributing darknet traffic to their root causes, prior works rely on improvised strategies to validate their method outputs. 
The defining practices of these strategies include whether they validate method outputs against labeled data, whether they incorporate external datasets 
(as used in their label definitions or more generally to cross-validate results), and whether outputs from baseline methods are used as a reference point for comparison.
We review these components, indicated in Table~\ref{tab:eval} for each work's validation strategy and consider the soundness and robustness of the overall approach.

Among our surveyed works, 7~\cite{2019evrard,2015nishikaze,2019iglesias,2016ban,2020han,2019kanehara,2023kartsioukas} employ strategies whose primary goals are 
to confirm results as part of exploratory analyses and often lack the use of labeled data, external datasets, and comparisons with baseline methods. 
The scope of these strategies are limited in-practice by the volume of method outputs and the amount of manual investigation efforts 
(\textit{e.g.}, application of domain knowledge to interpret traffic behavior and correlation of outputs with third-party reports) required for validation.
Most works~\cite{2019evrard,2015nishikaze,2019iglesias,2016ban,2020han,2019kanehara,2023kartsioukas} investigate a limited number of outputs, 
linked to targeted ports of botnet scans~\cite{linuxmoose} and remotely exploitable vulnerabilities~\cite{redis,adbminer,memcached}.
More extensive validation is conducted by~\cite{2020han,2019iglesias}, respectively classifying 1,634 alerts and inspecting 20 traffic clusters. 

% The remaing X surveyed works adopt validation strategies that we consider more robust.
% Several works~\cite{2019lagraa,2022zakroum,2020soro,2014bouharb}
% feature the use of external datasets to improve the credibility of their results. 
% For example,  Zakroum et al.~\cite{2022zakroum} correlate public vulnerability reports with anomalous traffic activity on specific TCP ports detected by their method.
% Bou-harb et al.~\cite{2014bouharb} resolve IP addresses of their highest-volume senders against passively-collected DNS data to infer whether scans originated from malicious domains.
% While they lack the use of external datasets, another set of works~\cite{2017ban,2021han} instead center their validation strategy on comparisons against baseline methods.
% A final group of works~\cite{2022kallitsis,2023zakroum,2019bouharb,2023han,2025abduaziz} rely on validation strategies that we consider the most robust.

Validation strategies employed by the remainder of works~\cite{2019lagraa,2022zakroum,2020soro,2014bouharb,2017ban,2021han,2022kallitsis,2023zakroum,2019bouharb,2023han,2025abduaziz} 
adopt practices that are more sound compared to those previously discussed.
These practices enlarge the scope of validation efforts and strengthen the credibility of results 
through cross-validation with external datasets, (\textit{e.g.}, national vulnerability disclosures~\cite{nistnvd}, passively-collected domain names~\cite{farsight}), 
and comparisons against baseline methodologies.
Of these, we highlight several works~\cite{2022kallitsis,2023zakroum,2019bouharb,2022han,2025abduaziz} specifically for the rigor of their strategies that combine all three practices.
Label definitions for traffic are explicit and well-defined (\textit{e.g.,} malware fingerprints~\cite{2019ceron} and publicly known addresses of research projects and search engines).

% For example, Zakroum et al.~\cite{@@} correlate public vulnerability reports with anomalous traffic activity on specific TCP ports. Bou-Harb et al.~\cite{@@} resolve IP addresses of their highest-volume senders against passively-collected DNS data to infer whether scans originated from blacklisted domains. 

% Since limited definitive "ground truth" exists for attributing darknet traffic to their root causes, 
% prior works rely on improvised strategies for validating their method outputs.
% The defining components of these strategies include their use of well-defined labeled data,
% whether they incorporate external datasets, and whether they use outputs of baseline methods
% as a reference point for comparison.
% We review these components, indicated in Table~\ref{tab:eval}, for each validation strategy to
% determine their soundness and robustness.

% Since limited definitive "ground truth" exists for attributing darknet traffic to their root causes, 
% prior works rely on improvised approaches to validate their method outputs.
% The defining components of these approaches include their use of labels (and more specifically the reliability of their definitions) 
% and whether outputs are cross-validated against external datasets and/or baseline methods. 
% % These components dictate the scale and rigor of each individual validation approach, which we define and group into three categories:
% These components, indicated in Table~\ref{tab:eval}, determine the soudness and robustness of each individual validation approach. 

% 8~\cite{2019evrard,2019lagraa,2015nishikaze,2019iglesias,2016ban,2020han,2019kanehara,2023kartsioukas} of our surveyed works apply 
% validation strategies suited for exploratory analyses.
% While the scope of validation varies across these works, it is limited in-practice by the volume of method outputs and the amount of 
% manual investigation efforts (\textit{e.g.}, application of domain knowledge to interpret traffic behavior, correlating findings to third-party reports)
% required to validate them.
% A majority works~\cite{2015nishikaze,2019kanehara,2023kartsioukas,2016ban,2019lagraa} investigate a limited number of their respective method outputs.
% Notable validated outputs range from botnet scans~\cite{@@}, targeted vulnerabilities~\cite{@@}.
% Others works~\cite{2019han,2019iglesias} examine a larger proportion of their method outputs though report 

% Of our surveyed works, we found 8~\cite{2019evrard,2019lagraa,2015nishikaze,2019iglesias,2016ban,2020han,2019kanehara,2023kartsioukas}
% that rely on purely internal validation approaches, which are often limited in scope and suited for the purpose of confirming exploratory analyses results. 
% While some approaches validate outputs against labels for metric computaiton, these labels are self-defined and thus may not have been subject to outside review.
% For example, \dots.

% that rely on purely internal validation approaches which typically reflect and are justified by the objective and scope of these works' assessments, 
% \textit{i.e.}, confirmation of exploratory analyses.
% Labels used to compute validation metrics are self-defined, i.e., based on human domain-expertise, and thus may not have been subject to outside review.
% Of our surveyed works, we found 8 

% The remaining 10 works offer

\begin{comment}
Since limited definitive "ground truth" exists for attributing darknet traffic to their root causes, prior works rely on improvised approaches to validate the meaningfulness of their method outputs.
These approaches differ in rigor depending on two characteristics: 
1) the use of labels (with varying degrees of confidence in their definitions); 
and 2) whether methods are cross-validated against other traffic datasets and/or compared against baseline methods. 
Using these characteristics, we define and group (Table~\ref{tab:eval}) validation approaches into three categories: A1, strictly internal or manual validation; A2; weak external validation; and A3, strong external validation. 
\end{comment}

\begin{comment}
% This yields two broad categories of validation: manual inspection with limited coverage, and systematic validation using external or curated data sources.
% We consider the soundness of method assessments by examining how prior works validate their method's detection outputs in the absence of well-defined ground truth; we identify 3 common approaches.
% In the first approach, authors~\cite{@@} manually inspect detection outputs and interpret their meaning. This non-exhaustive approach to validation serves to illustrate method capabilities in an exploratory manner.
% The second approach extends this process by cross-referencing detection outputs with external datasources, e.g., crowdsourced reports of scanners such as AbuseIPDB~\cite{@@}, \maxnote{enumerate}. Compared to the previous approach, confirmation provided by an additional source can improve confidence in result interpretations.
% The third and most formal approach involves constructing labeled datasets prior to assessment and computing accuracy metrics, e.g., conventional information retrieval metrics such as precision, recall, or F1-score, from subsequently obtained outputs combined with labeled samples. While this approach is the most reproducible, sound comparison of validation results depends on objective definitions for labels.
\end{comment}

% \begin{itemize}[leftmargin=*]
%     \item \textbf{A1 - Limited Internal Validation} 
%     Approaches which rely on solely internal validation metrics or limited-in-scope manual inspection of method outputs. 
%     \item \textbf{A2 - Weak External Validation}
%     Although these approaches use external validation metrics, label definitions vary in 
%     \item \textbf{A3 - Strong External Validation}
%     These approaches assess methods using validation metrics computed from 
% \end{itemize}

% Table~\ref{tab:eval} enumerates categories we assigned to each work. 

% A1 validation approaches include \cite{2019evrard,2019lagraa}.
% Some exceptions such as~\cite{2019evrard}, validates their model parameterization on an external dataset. but this dataset is collected from backbone traffic instead of a darknet.

% \noindent{\textbf{A1 - Strictly Internal/Manual Validation.}}
% Approaches that do not utilize ground-truth labels, relying solely on internal clustering metrics or manual inspection of the output.

% \noindent{\textbf{A2 - Weak External Validation.}}
% Approaches that incorporate external validation but rely on labels with uncertain confidence or lack sufficient cross-comparison 
% with other methods.

% \noindent{\textbf{A3 - Strong External Validation.}}
% The most rigorous approach, employing high-confidence ground-truth labels and validating results 
% through extensive cross-comparison with independent datasets or established techniques.


\mybox{Takeaways and Findings}{green!40}{green!10}{
\textbf{Takeaways:}
Improvised strategies that prior works use to validate the results of method assessments vary by the scope and soundness of their practices.
Nonetheless, we found a small subset of works whose strategies serve as a standard for the degree of rigor that validation strategies should aim towards.
% We find little uniformity across the defining factors of improvised strategies used to validate method assessments. 
% However, we find a small subset of works that set a standard for designing a robust validation strategy in the absence of defintiive ground-truth.
% \textbf{Takeaways:} 
% Most darknet detection methods operate under severe ground-truth limitations, resulting in a spectrum of validation rigor. 
% Internal-only validation remains the norm, weak external validation is common but inconsistent, and strong validation—while the most convincing—is rare. 
% As a consequence, it is often difficult to determine whether a method detects genuine Internet events or artifacts of the dataset and evaluation procedure.
}

\label{sec:assess:rep}
\subsection{Replicability of assessments}
We consider the replicability of method assessments based on whether prior works provide public access to:
1) the datasets used in experiments; and 
2) implementation of methods (as source code or their software artifacts) along with specifications of the computing environment used to run experiments.
These two elements are essential for reproducing published results and applying existing methods to new traffic datasets.
We consider a methodology replicable only when both conditions are satisified.
% To determine the replicability of each detection methodology, we assess whether prior works provide
% 1) public access to their implementation, such as source code or software artifacts; 
% and 2) specifications of the computing environment used to run experiments. 
% These two elements are essential for reproducing published results and for applying existing techniques to new traffic datasets. 
% We consider a methodology replicable only when both conditions are satisfied.

Less than a third of surveyed works provide source code of their implementations and roughly half detail specifications of their experimental computing environments.
Of readily-available source code, we found Python and R as the programming languages of choice. Both are popular among numeric and scientific communities given their ease-of-use for implementing analytics workflows and abundant open-source algorithmic libraries.
Other works such as ~\cite{2019lagraa,2014bouharb} rely on Java or C, which have become less popular as preferences shift towards higher-languages for analytics use-cases.

Environments used to run experiments range from personal laptop workstations~\cite{2025abduaziz,2017lagraa,2019lagraa} to small-scale research compute clusters~\cite{2022han,2019bouharb,2022zakroum}.
Cluster sizes do not exceed five servers, individually equipped with at most 256GB of memory.
Most implementations execute strictly on CPUs while a subset of works that leverage representation-learning techniques employ GPUs for model training and evaluation.
Across our surveyed works, release dates of the CPUs and GPUs trail publication dates by as much as 10 years.

\mybox{Takeaways and Findings}{green!40}{green!10}{

\textbf{Takeaways:} 
    Fewer than a third of the proposed detection methodologies qualify as replicable under our two criteria.
    However, these that do are implemented using widely-adopted programming languages and leverage accessible hardware for experiment execution.
}

% \section{A Need for A Systemized Evaluation of Darknet Event Detection Methodologies}
\section{Challenges to a comprehensive systematic assessment of methods}

Our survey of current existing method assessments revealed inconsistencies in their datasets, implementations, and the strategies 
used for validating their results.
In this section, we elaborate on these challenges and how they hinder a comprehensive assessment for rigorous comparisons.

\vspace{0.25em}
\noindent{\textbf{Limited replicability of detection methodologies.}} 
Despite our findings reported in Section~\ref{sec:assess:rep}, we found low reusability for source code released by the small fraction of works. 
Our own atttempts to execute this code resulted in failures, remediated only with substantial modifications. 
While the primary goal of these studies is to demonstrate and disseminate research ideas rather than deliver production-grade software, 
the quality of the code introduces friction for anyone attempting to reproduce results. 
Cumulatively, this effect produces a replicability gap that to address, requires attention and thought to the quality of released software.

\vspace{0.25em}
\noindent{\textbf{Few direct comparative assessments.}}
% Fewer than half of our surveyed works directly compare detection methodologies via evaluations on the same dataset.
A second constraint arises from the scarcity of direct comparisons between detection methodologies. 
In the ideal case, competing approaches would be evaluated on a shared dataset, enabling clear, controlled comparisons of their relative capabilities. 
Yet fewer than half of the surveyed works perform such within-dataset comparisons, and only a handful evaluate multiple detection frameworks side-by-side using the same traffic. 
As a result, the literature offers limited evidence about how methods relate to each other empirically. 
Instead, most evaluations are siloed within individual studies, making it difficult to reason about comparative performance, robustness, or applicability across deployment contexts. 
In several instances, no more than two frameworks have ever been demonstrated on the same underlying dataset, leaving open questions about how methodological differences translate into practical differences in detection outcomes.

% Evaluations that directly compare detection methodologies on the same dataset yield the most definitive results of their relative capabilities.
% Fewer than half of surveyed works fit this criteria 
% Evaluation of detection methodologies by directly comparing their Direct comparisons of detection methodologies yield
% Evaluation of detection methodologies  yield definitive results.
% Slightly fewer than half of our surveyed works evaluate their proposed methodology against a baseline methodology using the same dataset.
% Of those, use of a dataset does not extend beyond an individual work, i.e., real-world traffic datasets are not widely shared for researchers to evaluate their methodologies.

% \begin{enumerate}
%     \item direct comparisons of detection methodologies by evaluating them on the same dataset is the ideal scenario
%     \item Slightly fewer than half of surveyed works fit this criteria
% 	\item we can't reasonably compare frameworks by their performance on different datasets.
% 	\item Few works compare different frameworks on the same dataset
% 	\item What's the highest number of frameworks that use the same dataset?
% \end{enumerate}

\vspace{0.25em}
\noindent{\textbf{Non-overlapping datasets used for experimentation.}}
The challenge of comparison is further compounded by the heterogeneity of datasets used across studies. 
There is very little overlap in the traffic traces employed to evaluate frameworks: timeframes rarely coincide, traffic volumes often differ by multiple orders of magnitude, and data originate from distinct darknet deployments, network telescope sizes, and geographic vantage points. 
These non-overlapping datasets obscure whether observed performance reflects properties of the methodology or idiosyncrasies of the underlying traffic. 
Even when studies aim to detect similar classes of events, variation in temporal scope, probe density, and background traffic composition complicates any meaningful cross-paper interpretation. 
Collectively, this fragmentation of datasets reinforces the difficulty of establishing a unified baseline for evaluating darknet-based detection methods and highlights the need for shared, consistently curated datasets to support future methodological comparison.

% \begin{enumerate}
%     \item little overlap in the datasets used to evaluate frameworks
%     % \item evaluation of detection methodologies use darknet traffic sourced from a variety of telescopes over different timeframes
%     \item traffic volumes differ by multiple orders of magnitude.
%     \item different sources of traffic
%     \item mostly non-overlapping timeframes
% \end{enumerate}

\begin{comment}
\begin{table*}[h!]
    \small
    % \centering
    \setlength{\tabcolsep}{4pt}
    \caption{Details of empirical evaluation and traffic datasets found in our surveyed work. Appx. Table~\ref{tab:telescopes} summarizes referenced telescopes.}\label{tab:eval}
    \begin{tabular}{@{}lccccccccc@{}}
        \toprule
        & \multicolumn{1}{c}{\textbf{Compari-}} 
        & \multicolumn{2}{c}{\bf Replicability} 
        & \multicolumn{1}{c}{\textbf{Telescope(s)}} 
        & \multicolumn{4}{c}{\bf Dataset Attributes} 
        & \multicolumn{1}{c}{\textbf{Valid-}} \\
        \cmidrule(lr){3-4} \cmidrule(lr){6-9}
        \textbf{Work} & \textbf{son} & \textbf{Code} & \textbf{Specs} &  & \textbf{Duration} & \textbf{Year} & \textbf{Packets} & \textbf{Bytes} & \textbf{ations} \\
        \midrule

        Evrard et al.~\cite{2019evrard}
        & 
        &  & 
        & NT-3,6
        & 9M & 2015
        & 8M & ---
        & A1 \\

        Lagraa et al.\textbf{~\cite{2019lagraa}}~\cite{2017lagraa}
        &  
        &  & \cmark
        & NT-6
        & 2Y & 2014
        & 2B & 500 GB
        & A2 \\

        Soro et al.\textbf{~\cite{2020soro}}
        &  
        &  & 
        & NT-4,5
        & 3W,1D & 2020
        & --- & ---
        & A1 \\

        Nishikaze et al.~\cite{2015nishikaze}
        &  
        &  & 
        & NT-3
        & 28D & 2014
        & 303M & ---
        & A2 \\

        Kallitsis et al.~\cite{2022kallitsis}
        & \cite{2021gioacchini}
        & \cmark & \cmark
        & NT-2
        & 28D, 1D & 2016,2022
        & 49B, 3.1B & ---
        & A2, A3 \\

        Iglesias et al.~\cite{2019iglesias}
        &  
        &  & \cmark
        & NT-1
        & 6M & 2012
        & --- & 2.1 TB
        & A2 \\

        Gioacchini et al.\textbf{~\cite{2021gioacchini}}~\cite{2023gioacchini}
        & \cite{2020cohen,2017ring}
        & \cmark & \cmark
        & NT-4
        & 30d & 2021
        & 63M & ---
        & A1, A3 \\

        % Cohen et al.~\cite{2020cohen}
        % & \cite{2016ban}
        % &  & \cmark
        % & Ad hoc ($\approx$/22)
        % & 1y & 2019
        % & --- & $3+\,\mathrm{TB}$
        % & \wc{manual} \\

        Han et al.\textbf{~\cite{2020han}}~\cite{2022han}
        & \cite{2006takeuchi}
        & \cmark & \cmark
        & NT-3
        & 1M & 2018
        & --- & ---
        & A2 \\

        Han et al.\textbf{~\cite{2021han}}~\cite{2022han}
        & \cite{2020han,2006takeuchi,2019kanehara}
        & \cmark & 
        & NT-3
        & 1M & 2018
        & --- & ---
        & A2 \\

        Kanehara et al.\textbf{~\cite{2019kanehara}}~\cite{2022han}
        & \cite{2021han,2020han,2006takeuchi}
        & \cmark & \cmark
        & NT-3
        & 10M & 2017
        & --- & ---
        & A2 \\

        Kartsioukas et al.~\cite{2023kartsioukas}
        & \cite{2004lakhina}
        & \cmark & \cmark
        & NT-2
        & 1M & 2016
        & --- & ---
        & A1 \\

        Ban et al.~\cite{2017ban}
        & \cite{2012ban}
        &  & 
        & NT-3
        & --- & ---
        & --- & ---
        & A1 \\

        Ban et al.~\cite{2016ban}
        & 
        &  & 
        & NT-3
        & 1y & 2015
        & $3\times10^{7}$ & ---
        & A2 \\

        Bou-Harb et al.~\cite{2014bouharb}
        &  
        &  & 
        & NT-7
        & 2D & 2013
        & $10^6$ & 30GB
        & A2 \\

        Bou-Harb et al.\textbf{~\cite{2019bouharb}}~\cite{2015bouharb}
        & ~\cite{2018bouharb}
        &  & \cmark
        & NT-1,7
        & 1M,1M & 2016,2014
        & --- & 670GB, 240GB
        & A2 \\

        Zakroum et al.\textbf{~\cite{2022zakroum}}~\cite{2018zakroum}
        & ~\cite{2018zakroum}
        & & \cmark
        & NT-3,6
        & 3.5Y & 2017
        & --- & $1.5+\mathrm{TB}$
        & A2 \\

        Zakroum et al.~\cite{2023zakroum}
        & ~\cite{2023zakroum}
        & &
        & NT-3,6
        & 4.5Y & 2018
        & --- & ---
        & A3 \\

        \midrule
        \textbf{Aggregate}
        & 7/16
        & 4/16 & 7/16
        & 8-24
        & 1w--3.5y & 2012--2021
        & --- & ---
        & --- \\
        \bottomrule
    \end{tabular}
\end{table*}
\end{comment}

\label{sec:fw}
\section{Future Work}

We conclude this report by describing several directions for future work to overcome the barriers that hinder a complete comparative assessment of detection methods. 

\vspace{0.25em}
\noindent{\textbf{Curated darknet traffic datasets.}}
One way to lower the barrier to conducting such assessments is to improve the availability of curated reference datasets.
Such curation involves intentional selection of darknet traffic and enrichment using well-defined labels to assess method performance.
These label definitions may include the malicious senders reported by IP blocklists~\cite{abuseipdb,firehol}, 
known scanning organizations~\cite{2023collins}, 
and packet fingerprints tied to scanning tools~\cite{2024griffioen} or malware~\cite{2017antonakakis}.

% Sound benchmarking practice requires assessing method implementations on shared datasets. 
% By providing curated darknet-traffic datasets as inputs to our benchmarking framework, 
% we ensure that differences across outputs stem from the methods themselves rather than from inconsistencies in the data.
% The curation process involves intentional selection of traffic from specific darknets, sampled over historical time periods, ideally rich with known, landmark events. 
% Futher, labels accompany the traffic. \maxnote{elaborate}

\vspace{0.25em}
\noindent{\textbf{Consistent method implementations.}}
Consistency across the software used to implement methods and the execution environments that run assessments 
ensures the validity of performance metrics and improves interpretability of results.
While in-practice this is difficult to achieve when multiple parties reproduce assessments,
more thorough documentation (\textit{e.g.,} software libraries, CPUs, GPUs, memory, IO, and storage hardware components) 
can substitute for up to a degree of inconsistency.
% not only ensure the validity of computational performance results between different methods, 
% but also improves overall reproducibility of assessments by reducing the friction of executing source code.
% Practically, this may involve documentation of execution environments (\textit{e.g.}, CPUs, GPUs, memory, IO, and storage components)
% and alignment.

\vspace{0.25em}
\noindent{\textbf{Standardized validation strategies.}}
Enabled by labeled reference datasets and consistent method implementations, 
standard metrics to assess detection and computational performance are components of a standardized 
approach crucial to interpretation of assessment results.

% Enabled by assessments using shared reference datasets,
% conventional metrics (\textit{e.g.,} true/false positives/negatives and their derivative measures) 
% facilitate comparisons of method performance on labeled classes of traffic. 
% On the other hand, differential metrics (\textit{e.g.,} jaccard index) support comparisons 
% assessments using unlabeled traffic data. 

% \section{Acknowledgments}
% asadfadsf
% \section{Appendices}

\begin{table}[]
    \small
    \caption{Algorithms used by each surveyed framework.}
    \label{tab:frameworks-algorithms}
    % Use p{<width>} to allow wrapping of long algorithm lists.
    \begin{tabular}{lp{0.62\linewidth}}
        \toprule
        \textbf{Work} & \textbf{Algorithm(s)} \\
        \midrule
        Evrard et al.~\cite{2019evrard}                        & Dijkstra's~\cite{1959dijkstra}; K-NN~\cite{1967cover,1989fix} \\
        Lagraa et al.~\cite{2017lagraa,2019lagraa}             & Louvain~\cite{2006newman,2008blondel} \\
        Kallitsis et al.~\cite{2022kallitsis}                  & Autoencoder Dimensionality Reduction~\cite{2006hinton}; K-Means~\cite{1967macqueen} \\
        Iglesias et al.~\cite{2019iglesias}                    & K-Medoids~\cite{2009park}; Fuzzy-Gustafson~\cite{1999krishnapuram}; MAD-Thresholding~\cite{2004liu} \\
        Nishikaze et al.~\cite{2015nishikaze}                  & Hierarchical Clustering~\cite{2012murtagh} \\
        Soro et al.~\cite{2020soro}                            & Louvain Algorithm~\cite{2006newman,2008blondel} \\
        Gioacchini et al.~\cite{2021gioacchini,2023gioacchini} & Word2Vec~\cite{2013mikolov}; K-Means~\cite{1967macqueen}; K-NN~\cite{1967cover,1989fix}; Louvain~\cite{2006newman,2008blondel} \\
        Abduaziz et al.~\cite{2025abduaziz}                    & Word2Vec~\cite{2025abduaziz}; HDBScan~\cite{2013campello,2018gertrudes} \\
        Han et al.~\cite{2021han,2022han}                      & NMF~\cite{2000lee} \\
        Han et al.~\cite{2020han,2022han}                      & GLASSO~\cite{2008friedman} \\
        Kanehara et al.~\cite{2019kanehara,2022han}            & LRA-NTD~\cite{2015zhou}; FTSD~\cite{2010caiafa}; Otsu-Thresholding~\cite{1979otsu} \\
        Kartsioukas et al.~\cite{2023kartsioukas}              & Incremental PCA~\cite{2012arora} \\
        Ban et al.~\cite{2016ban}                              & Frequent Pattern Mining~\cite{2000han,2007han}; Hierarchical Clustering~\cite{2012murtagh} \\
        Torabi et al.~\cite{2020torabi,2018torabi}             & Association Rule Mining~\cite{1993agrawal}; DBSCAN~\cite{1996ester} \\
        Tanaka et al.~\cite{2023tanaka,2021tanaka}             & \textit{TODO} \\
        Niranjana et al.~\cite{2019niranjana}                  & PCA~\cite{1901pearson,1993hotelling} \\
        Cabana et al.~\cite{2019cabana}                        & Conduction Detection Algorithm~\cite{2015lu}; Fastcluster~\cite{2013mullner} \\
        Shaikh et al.~\cite{2018shaikh}                        & AdaBoost~\cite{@@}; Gradient Boosting~\cite{@@}; Random Forest~\cite{@@} \\
        Zakroum et al.~\cite{2022zakroum,2018zakroum}          & Spectral Clustering~\cite{2001ng}; LSTM~\cite{1997hochreiter} \\
        \bottomrule
    \end{tabular}
\end{table}


% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

\bibliographystyle{plain}
\bibliography{bib/refs.bib}

% \appendix
% \section{Research Methods}

% \subsection{Part One}

% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
% malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
% sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
% vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
% lacinia dolor. Integer ultricies commodo sem nec semper.

\end{document}
\endinput